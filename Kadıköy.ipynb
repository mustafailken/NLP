{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Yeni kadıköy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lafqy6D3dv9d",
        "colab_type": "code",
        "outputId": "91848785-17c2-40ff-9665-421a6042c361",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd9f9397-5c5c-4666-9bed-03ffff6b5e91\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-fd9f9397-5c5c-4666-9bed-03ffff6b5e91\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving EEVR_D-Evrak_iletisim_detay.xlsx to EEVR_D-Evrak_iletisim_detay.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HPsQawPd13E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "df = pd.read_excel('EEVR_D-Evrak_iletisim_detay.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fODvjx1zd-nX",
        "colab_type": "code",
        "outputId": "662cb7d4-858c-4094-e0b5-5d1c5ffd4c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = df.drop(columns={'Birim Adı','Evrak Türü','Doküman No','Kapsam','Geliş Şekli','Evrak Zaman','Evrak Sonuç Zaman','Hedef/Miat Tarihi','Evrak Sonuç Durum','Doküman Adres Pafta','Doküman Adres Mahalle','Doküman Adres Ada','Doküman Adres Parsel','Doküman Yer Adresi','Süre Durumu','İşlem Durumu','İşlem Yapılan Konu','İşlem Yapılan Alt Konu','İşlem Yapılan Süre','İşlem Yapılan Süre Birimi','Kurum Görüşü'})\n",
        "df = df.dropna(axis=0)\n",
        "df = df.drop_duplicates()\n",
        "df = df.reset_index(drop=True)\n",
        "df.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13711, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugOE2izCeuKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sayi = df['İşlem Süresi'].count() #for döngüsü için kaç tane değer olduğunu aldık\n",
        "time = [df['İşlem Süresi'][i][-18:-16] for i in range(sayi)] #İşlem Süresi kolonundaki değerlerin sadece gün sayılarını aldık\n",
        "\n",
        "df['İşlem Süresi'] = time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSN2hYpXQkzU",
        "colab_type": "code",
        "outputId": "fb02869b-8766-45f4-c667-b55fdf46175e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "\n",
        "print(df['İşlem Süresi'].value_counts().head(15))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     4548\n",
            "1     1741\n",
            "2     1696\n",
            "3     1141\n",
            "4      931\n",
            "5      664\n",
            "6      511\n",
            "7      398\n",
            "8      279\n",
            "9      216\n",
            "10     181\n",
            "11     145\n",
            "12     130\n",
            "13      92\n",
            "14      81\n",
            "Name: İşlem Süresi, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPSn298NewE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(df['İşlem Süresi'].value_counts().head(15))\n",
        "\n",
        "for i in range(len(df['İşlem Süresi'])):\n",
        "  if int(df['İşlem Süresi'][i]) < 1:\n",
        "    df['İşlem Süresi'][i] = '1'\n",
        "    \n",
        "  elif int(df['İşlem Süresi'][i]) < 4 and int(df['İşlem Süresi'][i]) >= 1:\n",
        "    df['İşlem Süresi'][i] = '3'\n",
        "    \n",
        "  elif int(df['İşlem Süresi'][i]) <= 10 and int(df['İşlem Süresi'][i]) >= 4:\n",
        "    df['İşlem Süresi'][i] = '5'\n",
        "  \n",
        "  else:\n",
        "    df['İşlem Süresi'][i] = '10'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNCnxXarGKYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "newpath = '/content/file' \n",
        "if not os.path.exists(newpath):\n",
        "    os.makedirs(newpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQTb-hJKmeVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.sample(frac=1)\n",
        "\n",
        "train_df = df[:12000]\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "\n",
        "test_df = df[12000:13000]\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "dev_df = df[13000:]\n",
        "dev_df = dev_df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rkcOgDwIUzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df_bert = pd.DataFrame({\n",
        "    'id':range(len(train_df)),\n",
        "    'label':train_df['İşlem Süresi'],\n",
        "    'alpha':['a']*train_df['İşlem Süresi'].shape[0],\n",
        "    'text': train_df['Doküman Metin'].replace(r'\\n', ' ', regex=True)# train_df_bert diye yeni bir dataframe oluşturduk berte vermeden önce bu hale getirmemiz gerekiyormuş\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-hLDOYEIiy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_df_bert = pd.DataFrame({\n",
        "    'id':range(len(dev_df)),\n",
        "    'label':dev_df['İşlem Süresi'],\n",
        "    'alpha':['a']*dev_df['İşlem Süresi'].shape[0],\n",
        "    'text': dev_df['Doküman Metin'].replace(r'\\n', ' ', regex=True)# train_df_bert diye yeni bir dataframe oluşturduk berte vermeden önce bu hale getirmemiz gerekiyormuş\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYJOXjF1I2jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df_bert = pd.DataFrame({\n",
        "    'id':range(len(test_df)),\n",
        "    'label':test_df['İşlem Süresi'],\n",
        "    'alpha':['a']*test_df['İşlem Süresi'].shape[0],\n",
        "    'text': test_df['Doküman Metin'].replace(r'\\n', ' ', regex=True)# train_df_bert diye yeni bir dataframe oluşturduk berte vermeden önce bu hale getirmemiz gerekiyormuş\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCg2_MvzDtTk",
        "colab_type": "code",
        "outputId": "fa77a96a-cab4-4094-bf29-d88f2416cd92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df_bert.head().shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Bc3gAvBpqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df_bert.to_csv('/content/file/train.tsv', index=False, sep=\"\\t\")\n",
        "test_df_bert.to_csv('/content/file/test.tsv', index=False, sep=\"\\t\")\n",
        "dev_df_bert.to_csv('/content/file/dev.tsv', index=False, sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t81_6C9KZPWY",
        "colab_type": "code",
        "outputId": "a6261f4e-53dd-4f51-a533-734ec3920f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/e3/389c2dd8d0e6ca1d8fad11aa4940e8df6909a26a5d954c0eff01f0d78b57/flair-0.4.3-py3-none-any.whl (180kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 20.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 81kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 92kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 122kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 143kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 153kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 163kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 174kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 8.8MB/s \n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting regex (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 57.6MB/s \n",
            "\u001b[?25hCollecting pytorch-transformers>=1.1.0 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Collecting langdetect (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 24.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from flair) (0.2.0)\n",
            "Collecting deprecated>=1.2.4 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/88/0e/9d5a1a8cd7130c49334cce7b8167ceda63d6a329c8ea65b626116bc9e9e6/Deprecated-1.2.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.3)\n",
            "Collecting bpemb>=0.2.9 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Collecting torch>=1.1.0 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 25kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.3)\n",
            "Collecting segtok>=1.5.7 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Collecting ipython==7.6.1 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2c/c7d44277b599df35af734d8f4142d501192fdb7aef5d04daf882d7eccfbc/ipython-7.6.1-py3-none-any.whl (774kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 50.4MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 49.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece (from pytorch-transformers>=1.1.0->flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers>=1.1.0->flair) (1.16.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers>=1.1.0->flair) (1.9.205)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers>=1.1.0->flair) (2.21.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.8.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.5.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.1.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (41.2.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (7.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.3.2)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from ipython==7.6.1->flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 56.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.4.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.15.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.1.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.7.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (2.1.3)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.205 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers>=1.1.0->flair) (1.12.205)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers>=1.1.0->flair) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers>=1.1.0->flair) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers>=1.1.0->flair) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers>=1.1.0->flair) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers>=1.1.0->flair) (3.0.4)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.13.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.7)\n",
            "Requirement already satisfied: parso>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.5.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch-transformers>=1.1.0->flair) (0.14)\n",
            "Building wheels for collected packages: sqlitedict, regex, langdetect, segtok, mpld3\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=4d7ab31c853d70183a8c67c34d0e0191542ac79f13ab3cc1e947869fdf5b1b05\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609221 sha256=44bd6cf9430e545c3b29246cf0fec69cdc4cc02e59d8708dda0317e815513a9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=ffce876fa3d436065fddff8c56fbeb6b03f51eb889b2decb41bba2f06527d7fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23257 sha256=e42f05bdb987ecfc587cc3ab72b404f487e90330b6416602d0a49a080ddd6fa7\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=e883fb503b11a6d92f772cb61da4ac616b75f3b86d2421275a17b96d0d223f4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "Successfully built sqlitedict regex langdetect segtok mpld3\n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.6.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sqlitedict, regex, torch, sentencepiece, pytorch-transformers, langdetect, deprecated, bpemb, segtok, prompt-toolkit, ipython, mpld3, flair\n",
            "  Found existing installation: torch 1.0.0\n",
            "    Uninstalling torch-1.0.0:\n",
            "      Successfully uninstalled torch-1.0.0\n",
            "  Found existing installation: prompt-toolkit 1.0.16\n",
            "    Uninstalling prompt-toolkit-1.0.16:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.16\n",
            "  Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.6 flair-0.4.3 ipython-7.6.1 langdetect-1.0.7 mpld3-0.3 prompt-toolkit-2.0.9 pytorch-transformers-1.1.0 regex-2019.8.19 segtok-1.5.7 sentencepiece-0.1.83 sqlitedict-1.6.0 torch-1.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-gCYfDfmaPr",
        "colab_type": "code",
        "outputId": "e393deec-cd43-4780-c528-70d26cacf34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
        "from typing import List\n",
        "\n",
        "# 1. get the corpus\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/file'\n",
        "\n",
        "# column format indicating which columns hold the text and label(s)\n",
        "column_name_map = {3: \"text\", 1: \"label\", 2: \"id\"}\n",
        "\n",
        "# load corpus containing training, test and dev data and if CSV has a header, you can skip it\n",
        "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
        "                                         column_name_map,\n",
        "                                         skip_header=True,\n",
        "                                         delimiter='\\t',    # tab-separated files\n",
        ")  \n",
        "\n",
        "  \n",
        "# 2. what tag do we want to predict?\n",
        "tag_type = 'ner'\n",
        "\n",
        "\n",
        "# 3. make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary('label')\n",
        "print(tag_dictionary.idx2item)\n",
        "\n",
        "# 4. initialize embeddings\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "\n",
        "    WordEmbeddings('glove'),\n",
        "\n",
        "    # comment in this line to use character embeddings\n",
        "    # CharacterEmbeddings(),\n",
        "\n",
        "    # comment in these lines to use flair embeddings\n",
        "    # FlairEmbeddings('news-forward'),\n",
        "    # FlairEmbeddings('news-backward'),\n",
        "]\n",
        "\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "# 5. initialize sequence tagger\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type=tag_type,\n",
        "                                        use_crf=True)\n",
        "\n",
        "# 6. initialize trainer\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. start training\n",
        "trainer.train('resources/taggers/example-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=10)\n",
        "\n",
        "# 8. plot weight traces (optional)\n",
        "from flair.visual.training_curves import Plotter\n",
        "plotter = Plotter()\n",
        "plotter.plot_weights('resources/taggers/example-ner/weights.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-28 15:21:02,994 Reading data from /content/file\n",
            "2019-08-28 15:21:02,995 Train: /content/file/train.tsv\n",
            "2019-08-28 15:21:02,996 Dev: /content/file/dev.tsv\n",
            "2019-08-28 15:21:02,997 Test: /content/file/test.tsv\n",
            "[b'<unk>', b'O', b'', b'<START>', b'<STOP>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-08-28 15:21:13,667 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:21:13,669 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=5, bias=True)\n",
            ")\"\n",
            "2019-08-28 15:21:13,671 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:21:13,671 Corpus: \"Corpus: 12000 train + 711 dev + 1000 test sentences\"\n",
            "2019-08-28 15:21:13,672 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:21:13,673 Parameters:\n",
            "2019-08-28 15:21:13,674  - learning_rate: \"0.1\"\n",
            "2019-08-28 15:21:13,675  - mini_batch_size: \"32\"\n",
            "2019-08-28 15:21:13,676  - patience: \"3\"\n",
            "2019-08-28 15:21:13,677  - anneal_factor: \"0.5\"\n",
            "2019-08-28 15:21:13,678  - max_epochs: \"10\"\n",
            "2019-08-28 15:21:13,679  - shuffle: \"True\"\n",
            "2019-08-28 15:21:13,680  - train_with_dev: \"False\"\n",
            "2019-08-28 15:21:13,681 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:21:13,682 Model training base path: \"resources/taggers/example-ner\"\n",
            "2019-08-28 15:21:13,683 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:21:13,684 Device: cuda:0\n",
            "2019-08-28 15:21:13,686 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:21:13,687 Embeddings storage mode: cpu\n",
            "2019-08-28 15:21:13,689 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:21:14,987 epoch 1 - iter 0/375 - loss 28.93586922 - samples/sec: 2972.27\n",
            "2019-08-28 15:21:26,421 epoch 1 - iter 37/375 - loss 1.31811898 - samples/sec: 106.50\n",
            "2019-08-28 15:21:36,253 epoch 1 - iter 74/375 - loss 0.67737027 - samples/sec: 124.03\n",
            "2019-08-28 15:21:47,362 epoch 1 - iter 111/375 - loss 0.45715998 - samples/sec: 122.01\n",
            "2019-08-28 15:21:58,250 epoch 1 - iter 148/375 - loss 0.34549093 - samples/sec: 111.05\n",
            "2019-08-28 15:22:09,650 epoch 1 - iter 185/375 - loss 0.27784576 - samples/sec: 118.10\n",
            "2019-08-28 15:22:19,962 epoch 1 - iter 222/375 - loss 0.23245073 - samples/sec: 117.57\n",
            "2019-08-28 15:22:32,762 epoch 1 - iter 259/375 - loss 0.19988834 - samples/sec: 103.45\n",
            "2019-08-28 15:22:44,277 epoch 1 - iter 296/375 - loss 0.17536554 - samples/sec: 105.05\n",
            "2019-08-28 15:22:55,581 epoch 1 - iter 333/375 - loss 0.15622896 - samples/sec: 118.89\n",
            "2019-08-28 15:23:05,544 epoch 1 - iter 370/375 - loss 0.14087142 - samples/sec: 121.61\n",
            "2019-08-28 15:23:06,986 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:23:06,989 EPOCH 1 done: loss 0.1394 - lr 0.1000\n",
            "2019-08-28 15:23:17,073 DEV : loss 0.0018645846284925938 - score 0.0\n",
            "2019-08-28 15:23:17,894 BAD EPOCHS (no improvement): 0\n",
            "2019-08-28 15:23:20,998 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:23:22,153 epoch 2 - iter 0/375 - loss 0.00291935 - samples/sec: 4010.46\n",
            "2019-08-28 15:23:32,729 epoch 2 - iter 37/375 - loss 0.00197556 - samples/sec: 115.20\n",
            "2019-08-28 15:23:43,177 epoch 2 - iter 74/375 - loss 0.00192775 - samples/sec: 116.39\n",
            "2019-08-28 15:23:55,669 epoch 2 - iter 111/375 - loss 0.00180473 - samples/sec: 107.60\n",
            "2019-08-28 15:24:06,228 epoch 2 - iter 148/375 - loss 0.00170647 - samples/sec: 114.98\n",
            "2019-08-28 15:24:18,709 epoch 2 - iter 185/375 - loss 0.00163041 - samples/sec: 105.81\n",
            "2019-08-28 15:24:29,881 epoch 2 - iter 222/375 - loss 0.00157077 - samples/sec: 108.48\n",
            "2019-08-28 15:24:40,830 epoch 2 - iter 259/375 - loss 0.00151248 - samples/sec: 123.71\n",
            "2019-08-28 15:24:50,817 epoch 2 - iter 296/375 - loss 0.00145709 - samples/sec: 121.54\n",
            "2019-08-28 15:25:01,992 epoch 2 - iter 333/375 - loss 0.00140674 - samples/sec: 120.51\n",
            "2019-08-28 15:25:13,064 epoch 2 - iter 370/375 - loss 0.00136020 - samples/sec: 109.18\n",
            "2019-08-28 15:25:14,283 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:25:14,285 EPOCH 2 done: loss 0.0014 - lr 0.1000\n",
            "2019-08-28 15:25:24,513 DEV : loss 0.0007882363861426711 - score 0.0\n",
            "2019-08-28 15:25:25,321 BAD EPOCHS (no improvement): 1\n",
            "2019-08-28 15:25:28,432 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:25:29,630 epoch 3 - iter 0/375 - loss 0.00079870 - samples/sec: 2605.71\n",
            "2019-08-28 15:25:40,260 epoch 3 - iter 37/375 - loss 0.00088018 - samples/sec: 115.35\n",
            "2019-08-28 15:25:51,841 epoch 3 - iter 74/375 - loss 0.00083770 - samples/sec: 117.84\n",
            "2019-08-28 15:26:02,679 epoch 3 - iter 111/375 - loss 0.00081450 - samples/sec: 111.72\n",
            "2019-08-28 15:26:13,431 epoch 3 - iter 148/375 - loss 0.00079517 - samples/sec: 112.54\n",
            "2019-08-28 15:26:24,093 epoch 3 - iter 185/375 - loss 0.00078170 - samples/sec: 127.20\n",
            "2019-08-28 15:26:35,463 epoch 3 - iter 222/375 - loss 0.00076408 - samples/sec: 106.45\n",
            "2019-08-28 15:26:47,354 epoch 3 - iter 259/375 - loss 0.00075312 - samples/sec: 112.29\n",
            "2019-08-28 15:26:58,575 epoch 3 - iter 296/375 - loss 0.00073673 - samples/sec: 107.74\n",
            "2019-08-28 15:27:09,458 epoch 3 - iter 333/375 - loss 0.00071858 - samples/sec: 124.80\n",
            "2019-08-28 15:27:20,311 epoch 3 - iter 370/375 - loss 0.00070693 - samples/sec: 111.35\n",
            "2019-08-28 15:27:21,667 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:27:21,668 EPOCH 3 done: loss 0.0007 - lr 0.1000\n",
            "2019-08-28 15:27:31,795 DEV : loss 0.00048153390525840223 - score 0.0\n",
            "2019-08-28 15:27:32,620 BAD EPOCHS (no improvement): 2\n",
            "2019-08-28 15:27:35,765 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:27:37,004 epoch 4 - iter 0/375 - loss 0.00055897 - samples/sec: 2605.37\n",
            "2019-08-28 15:27:48,671 epoch 4 - iter 37/375 - loss 0.00055027 - samples/sec: 104.46\n",
            "2019-08-28 15:27:58,256 epoch 4 - iter 74/375 - loss 0.00054504 - samples/sec: 127.31\n",
            "2019-08-28 15:28:10,029 epoch 4 - iter 111/375 - loss 0.00052911 - samples/sec: 114.81\n",
            "2019-08-28 15:28:21,142 epoch 4 - iter 148/375 - loss 0.00051782 - samples/sec: 108.59\n",
            "2019-08-28 15:28:33,128 epoch 4 - iter 185/375 - loss 0.00051371 - samples/sec: 111.23\n",
            "2019-08-28 15:28:44,850 epoch 4 - iter 222/375 - loss 0.00050448 - samples/sec: 103.59\n",
            "2019-08-28 15:28:57,261 epoch 4 - iter 259/375 - loss 0.00049104 - samples/sec: 97.20\n",
            "2019-08-28 15:29:07,808 epoch 4 - iter 296/375 - loss 0.00048195 - samples/sec: 115.16\n",
            "2019-08-28 15:29:18,752 epoch 4 - iter 333/375 - loss 0.00047227 - samples/sec: 122.74\n",
            "2019-08-28 15:29:28,908 epoch 4 - iter 370/375 - loss 0.00046653 - samples/sec: 119.25\n",
            "2019-08-28 15:29:30,090 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:29:30,094 EPOCH 4 done: loss 0.0005 - lr 0.1000\n",
            "2019-08-28 15:29:40,191 DEV : loss 0.00034607364796102047 - score 0.0\n",
            "2019-08-28 15:29:41,000 BAD EPOCHS (no improvement): 3\n",
            "2019-08-28 15:29:44,136 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:29:45,355 epoch 5 - iter 0/375 - loss 0.00034916 - samples/sec: 3235.18\n",
            "2019-08-28 15:29:55,407 epoch 5 - iter 37/375 - loss 0.00039450 - samples/sec: 121.62\n",
            "2019-08-28 15:30:06,783 epoch 5 - iter 74/375 - loss 0.00039342 - samples/sec: 119.59\n",
            "2019-08-28 15:30:18,271 epoch 5 - iter 111/375 - loss 0.00038369 - samples/sec: 104.88\n",
            "2019-08-28 15:30:29,181 epoch 5 - iter 148/375 - loss 0.00037939 - samples/sec: 111.06\n",
            "2019-08-28 15:30:40,289 epoch 5 - iter 185/375 - loss 0.00037484 - samples/sec: 109.30\n",
            "2019-08-28 15:30:51,085 epoch 5 - iter 222/375 - loss 0.00036748 - samples/sec: 112.21\n",
            "2019-08-28 15:31:03,035 epoch 5 - iter 259/375 - loss 0.00036278 - samples/sec: 112.09\n",
            "2019-08-28 15:31:13,513 epoch 5 - iter 296/375 - loss 0.00036300 - samples/sec: 115.76\n",
            "2019-08-28 15:31:25,692 epoch 5 - iter 333/375 - loss 0.00035940 - samples/sec: 110.03\n",
            "2019-08-28 15:31:36,392 epoch 5 - iter 370/375 - loss 0.00035669 - samples/sec: 113.03\n",
            "2019-08-28 15:31:37,953 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:31:37,957 EPOCH 5 done: loss 0.0004 - lr 0.1000\n",
            "2019-08-28 15:31:48,008 DEV : loss 0.000261746026808396 - score 0.0\n",
            "Epoch     4: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-08-28 15:31:48,835 BAD EPOCHS (no improvement): 4\n",
            "2019-08-28 15:31:51,945 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:31:53,103 epoch 6 - iter 0/375 - loss 0.00025928 - samples/sec: 2504.69\n",
            "2019-08-28 15:32:04,210 epoch 6 - iter 37/375 - loss 0.00029996 - samples/sec: 110.32\n",
            "2019-08-28 15:32:16,873 epoch 6 - iter 74/375 - loss 0.00030363 - samples/sec: 106.02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-323:\n",
            "Process Process-319:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-08-28 15:32:25,987 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-28 15:32:25,998 Exiting from training early.\n",
            "2019-08-28 15:32:26,003 Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fed45709f28>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 50, in wait\n",
            "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 28, in poll\n",
            "    pid, sts = os.waitpid(self.pid, flag)\n",
            "KeyboardInterrupt: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, learning_rate, mini_batch_size, eval_mini_batch_size, max_epochs, anneal_factor, patience, min_learning_rate, train_with_dev, monitor_train, monitor_test, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, shuffle, param_selection_mode, num_workers, sampler, use_amp, amp_opt_level, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward_loss\u001b[0;34m(self, data_points, sort)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m_calculate_loss\u001b[0;34m(self, features, sentences)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mforward_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mgold_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m_score_sentence\u001b[0;34m(self, feats, tags, lens_)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 ]\n\u001b[0;32m--> 506\u001b[0;31m             ) + torch.sum(feats[i, r, tags[i, : lens_[i]]])\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-cc74a3ed0f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m               \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m               \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m               max_epochs=10)\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# 8. plot weight traces (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, learning_rate, mini_batch_size, eval_mini_batch_size, max_epochs, anneal_factor, patience, min_learning_rate, train_with_dev, monitor_train, monitor_test, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, shuffle, param_selection_mode, num_workers, sampler, use_amp, amp_opt_level, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam_selection_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"final-model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/nn.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, model_file)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     def save_checkpoint(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_id\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mserialized_storages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;31m# FIXME: the docs say that persistent_id should only return a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# but torch store returns tuples. This works only in the binary protocol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "912UKu3723w2",
        "colab_type": "code",
        "outputId": "e644be6b-aa8f-44c3-812c-ceae4b58e164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "a=corpus.obtain_statistics()\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"TRAIN\": {\n",
            "        \"dataset\": \"TRAIN\",\n",
            "        \"total_number_of_documents\": 12000,\n",
            "        \"number_of_documents_per_class\": {\n",
            "            \"3\": 4032,\n",
            "            \"1\": 3964,\n",
            "            \"5\": 2769,\n",
            "            \"10\": 1235\n",
            "        },\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 393015,\n",
            "            \"min\": 1,\n",
            "            \"max\": 491,\n",
            "            \"avg\": 32.75125\n",
            "        }\n",
            "    },\n",
            "    \"TEST\": {\n",
            "        \"dataset\": \"TEST\",\n",
            "        \"total_number_of_documents\": 1000,\n",
            "        \"number_of_documents_per_class\": {\n",
            "            \"5\": 245,\n",
            "            \"1\": 340,\n",
            "            \"3\": 319,\n",
            "            \"10\": 96\n",
            "        },\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 33827,\n",
            "            \"min\": 1,\n",
            "            \"max\": 441,\n",
            "            \"avg\": 33.827\n",
            "        }\n",
            "    },\n",
            "    \"DEV\": {\n",
            "        \"dataset\": \"DEV\",\n",
            "        \"total_number_of_documents\": 711,\n",
            "        \"number_of_documents_per_class\": {\n",
            "            \"1\": 244,\n",
            "            \"3\": 229,\n",
            "            \"5\": 168,\n",
            "            \"10\": 70\n",
            "        },\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 22533,\n",
            "            \"min\": 2,\n",
            "            \"max\": 269,\n",
            "            \"avg\": 31.69198312236287\n",
            "        }\n",
            "    }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LVRHBqpkJeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Sentence(texts):\n",
        "  tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "  tokenizer.fit_on_texts(texts)\n",
        "  sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "  word_index = tokenizer.word_index\n",
        "  print('Number of Unique Tokens',len(word_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbRMrrn6Osln",
        "colab_type": "code",
        "outputId": "63cdb3d5-a8ce-4fe7-ec45-bc3a6202ac59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "for i in len(df['İşlem Süresi']):\n",
        "  df[]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Doküman Metin</th>\n",
              "      <th>İşlem Süresi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Doküman Metin, İşlem Süresi]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSWnG7f7OH-4",
        "colab_type": "code",
        "outputId": "288b3359-8c91-4fd1-c1a3-9982b113514d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(df['İşlem Süresi'][13658])\n",
        "df['Doküman Metin'][13658]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Merhaba, Kadıköyde yapılan yeni binaların çoğunun içerisinde acil çıkış kapısı var. Bu hırsızlara davet çıkarıyor ki duyuyoruz bu sebepten olan hırsızlıkları. Bu konuda bir düzenleme yapacak mısınız? Ev tutmaya çalışıyoruz ama bu sebepten ev bulamıyoruz.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4rQePQ-Bol7",
        "colab_type": "code",
        "outputId": "eb65d1bc-8bf6-4d9e-9bc1-62eb6c17d960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "model = SequenceTagger.load('resources/taggers/example-ner/final-model.pt')\n",
        "\n",
        "# create example sentence\n",
        "sentence = Sentence('I love Berlin')\n",
        "\n",
        "# predict tags and print\n",
        "model.predict(sentence)\n",
        "\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-28 17:11:36,729 loading file resources/taggers/example-ner/final-model.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-629ba588ce7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resources/taggers/example-ner/final-model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# create example sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'I love Berlin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/nn.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m# see https://github.com/zalandoresearch/flair/issues/351\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_big_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_model_with_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ]
    }
  ]
}